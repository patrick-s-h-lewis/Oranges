{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Generator\n",
    "Generates a corpus for training using the titles of CamHarvestCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import string\n",
    "import codecs\n",
    "import gensim \n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import re\n",
    "punct_filter = [u'\"',u'#',u'$',u'%',u'&',u'\\\\',u\"'\",u'(',u')',u'*',u'+',u',',u'.',u'/',\n",
    "     u'-',u':',u';',u'<',u'=',u'>',u'?',u'@',u'[',u']',u'^',u'_',u'`',u'{',\n",
    "     u'|',u'}',u'–',u'\\u2013',u'\\u2010',u'\\u2212',u'\\u2018',u'\\u2019',u'\\u2022',u'\\u2020',u'\\u00B0',u'\\u29B9',u'\\uFF0D',u'\\u2261']\n",
    "stop = stopwords.words('english')\n",
    "#mongo_url = 'mongodb://localhost:6666/'\n",
    "mongo_url = 'mongodb://localhost:27017/'\n",
    "db = 'Cherry'\n",
    "coll_in = 'Cranberry'\n",
    "client = MongoClient(mongo_url)\n",
    "ch = client[db][coll_in]\n",
    "coops = client[db]['raspberry']\n",
    "#corpusfile = 'corpus2.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GensimCorpus(object):\n",
    "    def __init__(self,corpus_text_file,diction):\n",
    "        self.corpus_text_file = corpus_text_file\n",
    "        self.dictionary = diction\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in open(self.corpus_text_file):\n",
    "            yield self.dictionary.doc2bow(line.split())\n",
    "\n",
    "def dictionary_generator(corpus_file):\n",
    "    dictionary = corpora.Dictionary(line.split() for line in open(corpus_file))\n",
    "    return dictionary\n",
    "\n",
    "def create_models(corpus_file):\n",
    "    dictionary = dictionary_generator(corpus_file)\n",
    "    print('Created Dictionary')\n",
    "    corp = GensimCorpus(corpus_file,dictionary)\n",
    "    print('Created Corpus Object')\n",
    "    tfidf = models.TfidfModel(corp)\n",
    "    print('Created TFIDF Model')\n",
    "    tfidf_corp = tfidf[corp]\n",
    "    print('Created TFIDF Corpus')\n",
    "    return dictionary,corp,tfidf,tfidf_corp\n",
    "\n",
    "def load_models(dictionary_file,corpus_file,tfidf_file):\n",
    "    dictionary = corpora.Dictionary.load(dictionary_file)\n",
    "    corp = GensimCorpus(corpus_file,dictionary)\n",
    "    tfidf = models.TfidfModel.load(tfidf_file)\n",
    "    tfidf_corp = tfidf[corp]\n",
    "    return dictionary,corp,tfidf,tfidf_corp\n",
    "\n",
    "def tfidf_filtered_corpus_generator(threshold):\n",
    "    corpus_filename = 'tfidf_filtered_'+str(threshold).strip('.')+'.txt'\n",
    "    ind=0\n",
    "    with codecs.open(corpus_filename,'a',encoding='utf8') as f:\n",
    "        for doc in tfidf_corp:\n",
    "            if ind%500000 == 0:\n",
    "                print(ind)\n",
    "            f.write(' '.join([dictionary[i] for i,j in doc if j>=threshold]))\n",
    "            f.write('\\n')\n",
    "            ind+=1\n",
    "\n",
    "def raw_corpus_generator(file_name):\n",
    "    ind = 0 \n",
    "    with codecs.open(file_name,'a',encoding='utf8') as f:\n",
    "        for rec in ch.find({'crossref_doi':True}):\n",
    "            lt = rec['title'].lower()\n",
    "            slt = lt.strip()\n",
    "            tslt = slt.translate(punct_filter)\n",
    "            export = tslt+u'\\n'\n",
    "            f.write(export)\n",
    "            ind+=1\n",
    "            if ind%100000==0:\n",
    "                print(ind)\n",
    "\n",
    "def remove_unicode_punct(subj, chars):\n",
    "    return re.sub(u'(?u)[' + re.escape(''.join(chars)) + ']', ' ', subj)\n",
    "                \n",
    "def sanitise(title):\n",
    "    lt = title.lower()\n",
    "    slt = lt.strip()\n",
    "    tslt = remove_unicode_punct(slt,punct_filter)\n",
    "    stop_filtered = [i for i in tslt.split() if i not in stop]\n",
    "    export = u' '.join(stop_filtered)\n",
    "    return export\n",
    "\n",
    "def create_stopword_filtered_corpus(file_name):\n",
    "    ind = 0 \n",
    "    with codecs.open(file_name,'a',encoding='utf8') as f:\n",
    "        for rec in ch.find({'crossref_doi':True}):\n",
    "            f.write(sanitise(rec['title'])+'u\\n')\n",
    "            ind+=1\n",
    "            if ind%10000==0:\n",
    "                print(ind)\n",
    "                \n",
    "def create_stopword_filtered_raspberry_corpus(file_name):\n",
    "    ind = 0 \n",
    "    with codecs.open(file_name,'a',encoding='utf8') as f:\n",
    "        for rec in coops.find({'abstract': {'$exists': True}, '$where': \"this.abstract.length>0\"}):\n",
    "            san_title = sanitise(rec['title'])\n",
    "            san_abs = sanitise(rec['abstract'])\n",
    "            f.write(san_title+' '+san_abs+'\\n')\n",
    "            ind+=1\n",
    "            if ind%10000==0:\n",
    "                print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n"
     ]
    }
   ],
   "source": [
    "samples = [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "for samp in samples:\n",
    "    tfidf_filtered_corpus_generator(samp)\n",
    "    print('corpus generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary,corp,tfidf,tfidf_corp = load_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n"
     ]
    }
   ],
   "source": [
    "garbage = set()\n",
    "word_loss = 0\n",
    "threshold = 0.2\n",
    "ind=0\n",
    "for doc in tfidf_corp:\n",
    "    for i,j in doc:\n",
    "        if j<=threshold:\n",
    "            word_loss+=1\n",
    "            garbage.add(i)\n",
    "    ind+=1\n",
    "        if ind%100000==0:\n",
    "            print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chemistry\n",
      "heterocyclic\n",
      "green\n",
      "vanadium\n",
      "pesticide\n",
      "solution\n",
      "clinical\n",
      "⊂v\n",
      "general\n",
      "practical\n",
      "chimie\n",
      "fundamental\n",
      "schools\n",
      "sch3\n",
      "51771\n",
      "impact\n",
      "2011\n",
      "factor\n",
      "conservation\n",
      "art\n",
      "polish\n",
      "highlights\n",
      "medicinal\n",
      "future\n",
      "n1\n",
      "benzothiepino\n",
      "scientific\n",
      "committee\n",
      "fifty\n",
      "years\n",
      "food\n",
      "note\n",
      "–\n",
      "quantum\n",
      "biology\n",
      "effects\n",
      "biological\n",
      "correction\n",
      "keith\n",
      "bioinorganic\n",
      "xv\n",
      "editorial\n",
      "6′\n",
      "calixarene\n",
      "40\n",
      "conference\n",
      "farber\n",
      "enzyme\n",
      "rechargeable\n",
      "bioorganic\n",
      "defined\n",
      "supramolecular\n",
      "iodovinyl\n",
      "nitration\n",
      "computational\n",
      "theoretical\n",
      "mechanical\n",
      "anniversary\n",
      "glossary\n",
      "renewable\n",
      "preface\n",
      "z\n",
      "great\n",
      "phytoprostanes\n",
      "war\n",
      "congress\n",
      "european\n",
      "1st\n",
      "analytical\n",
      "space\n",
      "prof\n",
      "rosemary\n",
      "dr\n",
      "11h\n",
      "heteroatom\n",
      "coordination\n",
      "laser\n",
      "greece\n",
      "sweet\n",
      "education\n",
      "nuclear\n",
      "organometallic\n",
      "light\n",
      "high\n",
      "material\n",
      "temperature\n",
      "solid\n",
      "state\n",
      "industry\n",
      "journal\n",
      "plasma\n",
      "phosphorus\n",
      "biomolecular\n",
      "pharmaceutical\n",
      "boron\n",
      "solutions\n",
      "organic\n",
      "sulfur\n",
      "polymers\n",
      "website\n",
      "thieme\n",
      "beyond\n",
      "chlorine\n",
      "international\n",
      "survey\n",
      "carini\n",
      "india\n",
      "nature\n",
      "proceeding\n",
      "engineers\n",
      "physical\n",
      "indeno\n",
      "initial\n",
      "organotin\n",
      "northwestern\n",
      "interference\n",
      "automated\n",
      "present\n",
      "r\n",
      "thymidine\n",
      "versus\n",
      "chemical\n",
      "purposes\n",
      "monkey\n",
      "within\n",
      "dendrimer\n",
      "tetrahydropyrimidines\n",
      "introduction\n",
      "dimethylhexane\n",
      "research\n",
      "protection\n",
      "alkyne\n",
      "crop\n",
      "reviews\n",
      "2015\n",
      "main\n",
      "group\n",
      "electron\n",
      "molecular\n",
      "electrochemistry\n",
      "678\n",
      "macrocycles\n",
      "selena\n",
      "perspectives\n",
      "moscow\n",
      "workshop\n",
      "modern\n",
      "aspects\n",
      "c5h5\n",
      "new\n",
      "use\n",
      "guide\n",
      "writing\n",
      "2003\n",
      "tetrahedron\n",
      "creativity\n",
      "prize\n",
      "nucleic\n",
      "templates\n",
      "acid\n",
      "liebig\n",
      "animal\n",
      "proteomics\n",
      "emphasis\n",
      "contributions\n",
      "contents\n",
      "mch\n",
      "macromolecular\n",
      "symposia\n",
      "tetramethylethylenediaminium\n",
      "history\n",
      "year\n",
      "second\n",
      "life\n",
      "металлопротеиназы\n",
      "ideas\n",
      "louis\n",
      "entry\n",
      "medicine\n",
      "трансформированных\n",
      "laboratory\n",
      "photochemistry\n",
      "berzelius\n",
      "–liclo\n",
      "phenomena\n",
      "solubility\n",
      "energy\n",
      "development\n",
      "sustainable\n",
      "pharmaceuticals\n",
      "pharmacy\n",
      "large\n",
      "hospital\n",
      "importance\n",
      "environmental\n",
      "environment\n",
      "review\n",
      "experiment\n",
      "atmospheric\n",
      "bpy\n",
      "ace\n",
      "toxicological\n",
      "marine\n",
      "communication\n",
      "short\n",
      "trimethylenebipyridine\n",
      "three\n",
      "editors\n",
      "self\n",
      "10\n",
      "top\n",
      "cited\n",
      "articles\n",
      "aquatic\n",
      "mediterranean\n",
      "systems\n",
      "macrocyclic\n",
      "titanocene\n",
      "sulfide\n",
      "conferences\n",
      "2004\n",
      "dynamic\n",
      "adaptive\n",
      "towards\n",
      "ansell\n",
      "better\n",
      "teaching\n",
      "way\n",
      "house\n",
      "report\n",
      "national\n",
      "applied\n",
      "1904\n",
      "issue\n",
      "special\n",
      "pure\n",
      "surgeons\n",
      "role\n",
      "africa\n",
      "south\n",
      "moo4\n",
      "oxyhydroxide\n",
      "world\n",
      "iupac\n",
      "clean\n",
      "students\n",
      "human\n",
      "views\n",
      "reporting\n",
      "interlanthanide\n",
      "units\n",
      "news\n",
      "concentration\n",
      "regulation\n",
      "chemistry”\n",
      "russia\n",
      "spain\n",
      "arts\n",
      "scientists\n",
      "fight\n",
      "2009\n",
      "results\n",
      "reader\n",
      "2010\n",
      "2014\n",
      "frontiers\n",
      "france\n",
      "diphenylphosphine\n",
      "host\n",
      "useful\n",
      "guest\n",
      "techniques\n",
      "dft\n",
      "flavor\n",
      "replication\n",
      "recognition\n",
      "connected\n",
      "elementary\n",
      "inorganic\n",
      "experimental\n",
      "test\n",
      "methodology\n",
      "diagnostic\n",
      "nonsteroidal\n",
      "calendar\n",
      "index\n",
      "subject\n",
      "author\n",
      "oo·\n",
      "content\n",
      "aerosol\n",
      "impacts\n",
      "ocean\n",
      "recommendations\n",
      "integrity\n",
      "frontier\n",
      "2e\n",
      "front\n",
      "matter\n",
      "2993\n",
      "645\n",
      "publishers\n",
      "ane\n",
      "photography\n",
      "image\n",
      "azaindole\n",
      "erratum\n",
      "alloying\n",
      "diisocyanohexane\n",
      "division\n",
      "american\n",
      "association\n",
      "boltzmann\n",
      "diet\n",
      "bromo\n",
      "meeting\n",
      "symposium\n",
      "fifth\n",
      "7186\n",
      "board\n",
      "mercury\n",
      "trans\n",
      "mccleverty\n",
      "29213\n",
      "vii\n",
      "29328\n",
      "atm\n",
      "flow\n",
      "cinnamomum\n",
      "standards\n",
      "de\n",
      "790\n",
      "chlorobis\n",
      "book\n",
      "progress\n",
      "korea\n",
      "antioxidants\n",
      "quadrupole\n",
      "contractions\n",
      "memorial\n",
      "nutritional\n",
      "bibliography\n",
      "methods\n",
      "bath\n",
      "colour\n",
      "diamides\n",
      "publisher\n",
      "wei\n",
      "biocatalysis\n",
      "click\n",
      "member\n",
      "commentary\n",
      "events\n",
      "krohn\n",
      "octakis\n",
      "scotland\n",
      "cover\n",
      "crude\n",
      "oil\n",
      "biomarkers\n",
      "climate\n",
      "plans\n",
      "change\n",
      "probed\n",
      "spread\n",
      "like\n",
      "management\n",
      "ocho•\n",
      "hrtem\n",
      "hfs\n",
      "2013\n",
      "love\n",
      "air\n",
      "laiiicuii\n",
      "pd−oo−x\n",
      "bio\n",
      "armour\n",
      "scales\n",
      "tree\n",
      "o\n",
      "fuel\n",
      "processing\n",
      "synthesis\n",
      "chemist\n",
      "2007\n",
      "water\n",
      "…\n",
      "b315474b\n",
      "dangling\n",
      "farmed\n",
      "stark\n",
      "oxalato\n",
      "pigs\n",
      "phenazine\n",
      "germany\n",
      "abstracts\n",
      "phosphoinositide\n",
      "signaling\n",
      "ethoxycarbonyl\n",
      "inc\n",
      "list\n",
      "2005\n",
      "addresses\n",
      "cellular\n",
      "‘a\n",
      "ltd\n",
      "optimized\n",
      "biosciences\n",
      "au4\n",
      "malaria\n",
      "biotechnology\n",
      "5z\n",
      "limited\n",
      "isomorphous\n",
      "biotin\n",
      "synthase\n",
      "computers\n",
      "healthcare\n",
      "12a\n",
      "volume\n",
      "29\n",
      "28\n",
      "amidines\n",
      "foreword\n",
      "26\n",
      "increase\n",
      "price\n",
      "needs\n",
      "unesco\n",
      "vanloon\n",
      "0199228867\n",
      "0521736695\n",
      "22\n",
      "stimulus\n",
      "benzamide\n",
      "corrections\n",
      "butterfly\n",
      "universe\n",
      "1\n",
      "confirmed\n",
      "nh2me2\n",
      "perspective\n",
      "27\n",
      "genetics\n",
      "thiolate−phosphine\n",
      "pyrazolo\n",
      "past\n",
      "cultural\n",
      "sensors\n",
      "clinically\n",
      "stresses\n",
      "cocoa\n",
      "crystal\n",
      "isobutyl\n",
      "invited\n",
      "jack\n",
      "tb\n",
      "tubes\n",
      "line\n",
      "supply\n",
      "nanotechnology\n",
      "safety\n",
      "first\n",
      "o2cr\n",
      "trade\n",
      "award\n",
      "microwave\n",
      "protein\n",
      "erythrocytes\n",
      "adenosyl\n",
      "right\n",
      "side\n",
      "phsn\n",
      "tb3\n",
      "marilyn\n",
      "john\n",
      "diary\n",
      "validation\n",
      "constructed\n",
      "discovery\n",
      "ronald\n",
      "c\n",
      "h2so4\n",
      "power\n",
      "simple\n",
      "complexity\n",
      "local\n",
      "crook\n",
      "corrigendum\n",
      "polymer\n",
      "bench\n",
      "cram\n",
      "1994\n",
      "ionic\n",
      "liquids\n",
      "errata\n",
      "salt\n",
      "build\n",
      "greener\n",
      "diagnostik\n"
     ]
    }
   ],
   "source": [
    "for word in list(garbage)[0:500]:\n",
    "    print(dictionary[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ziphian(corp,di,file_name):\n",
    "    li = []\n",
    "    ind=0\n",
    "    for doc in corp:\n",
    "        li+=[i for i,j in doc]\n",
    "    c = Counter(li)\n",
    "    c_li = [(k,v) for k,v in c.items()]\n",
    "    c_li_s = sorted(c_li,key=lambda x: x[1],reverse=True)\n",
    "    with open(file_name,'ab+') as f:\n",
    "        f.write('[')\n",
    "        for k,v in c_li_s[:-1]:\n",
    "            ex = json.dumps([di[k],v])\n",
    "            f.write(ex)\n",
    "            f.write(',\\n')\n",
    "    ex = json.dumps([di[c_li_s[-1][0]],c_li_s[-1][1]])\n",
    "    f.write(ex)\n",
    "    f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file',)).History will not be written to the database.\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-a04e8e3b31b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mcreate_stopword_filtered_raspberry_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-67-a04e8e3b31b3>\u001b[0m in \u001b[0;36mcreate_stopword_filtered_raspberry_corpus\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'other_raspberry_corpus.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcoops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'abstract'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'$exists'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$where'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"this.abstract.length>0\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0msan_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0msan_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'abstract'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pl375/.conda/envs/Anaconda/lib/python2.7/site-packages/pymongo/cursor.pyc\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m                 return _db._fix_outgoing(self.__data.popleft(),\n\u001b[1;32m--> 980\u001b[1;33m                                          self.__collection)\n\u001b[0m\u001b[0;32m    981\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pl375/.conda/envs/Anaconda/lib/python2.7/site-packages/pymongo/database.pyc\u001b[0m in \u001b[0;36m_fix_outgoing\u001b[1;34m(self, son, collection)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_fix_outgoing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \"\"\"Apply manipulators to a SON object as it comes out of the database.\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_stopword_filtered_raspberry_corpus():\n",
    "    ind = 0 \n",
    "    with codecs.open('other_raspberry_corpus.txt','a',encoding='utf8') as f:\n",
    "        for rec in coops.find({'abstract': {'$exists': True}, '$where': \"this.abstract.length>0\"}):\n",
    "            san_title = sanitise(rec['title'])\n",
    "            san_abs = sanitise(rec['abstract'])\n",
    "            f.write(san_title+' '+san_abs+'\\n')\n",
    "            ind+=1\n",
    "            if ind%10000==0:\n",
    "                print(ind)\n",
    "\n",
    "create_stopword_filtered_raspberry_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = 'Teaching fundamental physical chemistry concepts such as the potential energy surface, transition state, and reaction path is a challenging task. The traditionally used oversimplified 2D representation of potential and free energy surfaces makes this task even more difficult and often confuses students. We show how this 2D representation can be expanded to more realistic potential and free energy surfaces by creating surface models using 3D printing technology. The printed models include potential energy surfaces for the hydrogen exchange reaction and for rotations of methyl groups in 1-fluoro-2-methylpropene calculated using quantum chemical methods. We also present several model surfaces created from analytical functions of two variables. These models include a free energy surface for protein folding, and potential energy surfaces for a linear triatomic molecule and surface adsorption, as well as simple double minimum, quadruple minimum, and parabolic surfaces. We discuss how these 3D models can be used in teaching different chemical kinetics, dynamics, and vibrational spectroscopy concepts including the potential energy surface, transition state, minimum energy reaction path, reaction trajectory, harmonic frequency, and anharmonicity.Keywords:  Upper-Division Undergraduate; Physical Chemistry; Hands-On Learning/Manipulatives; Quantum Chemistry; Kinetics; Molecular Mechanics/Dynamics; Spectroscopy\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teaching fundamental physical chemistry concepts potential energy surface  transition state  reaction path challenging task  traditionally used oversimplified 2d representation potential free energy surfaces makes task even difficult often confuses students  show 2d representation expanded realistic potential free energy surfaces creating surface models using 3d printing technology  printed models include potential energy surfaces hydrogen exchange reaction rotations methyl groups 1 fluoro 2 methylpropene calculated using quantum chemical methods  also present several model surfaces created analytical functions two variables  models include free energy surface protein folding  potential energy surfaces linear triatomic molecule surface adsorption  well simple double minimum  quadruple minimum  parabolic surfaces  discuss 3d models used teaching different chemical kinetics  dynamics  vibrational spectroscopy concepts including potential energy surface  transition state  minimum energy reaction path  reaction trajectory  harmonic frequency  anharmonicity keywords  upper division undergraduate  physical chemistry  hands on learning manipulatives  quantum chemistry  kinetics  molecular mechanics dynamics  spectroscopy'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_unicode_punct(' '.join([i for i in sample.lower().strip().split() if i not in stop]),punct_filter).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Dictionary\n",
      "Created Corpus Object\n",
      "Created TFIDF Model\n",
      "Created TFIDF Corpus\n"
     ]
    }
   ],
   "source": [
    "dictionary, corpus, tfidf_model,tfidf_corpus = create_models('first_raspberry_corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model.save('first_raspberry_tfidf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_corpus.save('first_tfidf_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
