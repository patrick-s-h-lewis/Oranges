{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Corpus Generator\n",
    "Generates a corpus for training using the titles of CamHarvestCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import string\n",
    "import codecs\n",
    "import gensim \n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "punct_filter = dict((ord(char), u' ') for char in '\"#$%&\\'()*+,./-:;<=>?@[\\\\]^_`{|}–′')   \n",
    "stop = stopwords.words('english')\n",
    "mongo_url = 'mongodb://localhost:6666/'\n",
    "db = 'Cherry'\n",
    "coll_in = 'Cranberry'\n",
    "client = MongoClient(mongo_url)\n",
    "ch = client[db][coll_in]\n",
    "#corpusfile = 'corpus2.txt' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GensimCorpus(object):\n",
    "    def __init__(self,corpus_text_file,diction):\n",
    "        self.corpus_text_file = corpus_text_file\n",
    "        self.dictionary = diction\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in open(self.corpus_text_file):\n",
    "            yield self.dictionary.doc2bow(line.split())\n",
    "\n",
    "def dictionary_generator(corpus_file):\n",
    "    dictionary = corpora.Dictionary(line.split() for line in open(corpus_file))\n",
    "    return dictionary\n",
    "\n",
    "def create_models():\n",
    "    dictionary = dictionary_generator('second_corpus.txt')\n",
    "    corp = GensimCorpus('second_corpus.txt',dictionary)\n",
    "    tfidf = models.TfidfModel(corp)\n",
    "    tfidf_corp = tfidf[corp]\n",
    "    return dictionary,corp,tfidf,tfidf_corp\n",
    "\n",
    "def load_models():\n",
    "    dictionary = corpora.Dictionary.load('second_dictionary')\n",
    "    corp = GensimCorpus('second_corpus.txt',dictionary)\n",
    "    tfidf = models.TfidfModel.load('second_tfidf')\n",
    "    tfidf_corp = tfidf[corp]\n",
    "    return dictionary,corp,tfidf,tfidf_corp\n",
    "\n",
    "def tfidf_filtered_corpus_generator(threshold):\n",
    "    corpus_filename = 'tfidf_filtered_'+str(threshold).strip('.')+'.txt'\n",
    "    ind=0\n",
    "    with codecs.open(corpus_filename,'a',encoding='utf8') as f:\n",
    "        for doc in tfidf_corp:\n",
    "            if ind%500000 == 0:\n",
    "                print(ind)\n",
    "            f.write(' '.join([dictionary[i] for i,j in doc if j>=threshold]))\n",
    "            f.write('\\n')\n",
    "            ind+=1\n",
    "\n",
    "def raw_corpus_generator():\n",
    "    ind = 0 \n",
    "    with codecs.open('raw_corpus.txt','a',encoding='utf8') as f:\n",
    "        for rec in ch.find({'crossref_doi':True}):\n",
    "            lt = rec['title'].lower()\n",
    "            slt = lt.strip()\n",
    "            tslt = slt.translate(punct_filter)\n",
    "            export = tslt+u'\\n'\n",
    "            f.write(export)\n",
    "            ind+=1\n",
    "            if ind%100000==0:\n",
    "                print(ind)\n",
    "\n",
    "def sanitise(title):\n",
    "    lt = title.lower()\n",
    "    slt = lt.strip()\n",
    "    tslt = slt.translate(punct_filter)\n",
    "    stop_filtered = [i for i in tslt.split() if i not in stop]\n",
    "    export = u' '.join(stop_filtered)+u'\\n'\n",
    "    return export\n",
    "\n",
    "def create_stopword_filtered_corpus():\n",
    "    ind = 0 \n",
    "    with codecs.open('second_corpus.txt','a',encoding='utf8') as f:\n",
    "        for rec in ch.find({'crossref_doi':True}):\n",
    "            f.write(sanitise(rec['title']))\n",
    "            ind+=1\n",
    "            if ind%10000==0:\n",
    "                print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "corpus generated\n"
     ]
    }
   ],
   "source": [
    "samples = [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "for samp in samples:\n",
    "    tfidf_filtered_corpus_generator(samp)\n",
    "    print('corpus generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary,corp,tfidf,tfidf_corp = load_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n"
     ]
    }
   ],
   "source": [
    "garbage = set()\n",
    "word_loss = 0\n",
    "threshold = 0.2\n",
    "ind=0\n",
    "for doc in tfidf_corp:\n",
    "    for i,j in doc:\n",
    "        if j<=threshold:\n",
    "            word_loss+=1\n",
    "            garbage.add(i)\n",
    "    ind+=1\n",
    "        if ind%100000==0:\n",
    "            print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chemistry\n",
      "heterocyclic\n",
      "green\n",
      "vanadium\n",
      "pesticide\n",
      "solution\n",
      "clinical\n",
      "⊂v\n",
      "general\n",
      "practical\n",
      "chimie\n",
      "fundamental\n",
      "schools\n",
      "sch3\n",
      "51771\n",
      "impact\n",
      "2011\n",
      "factor\n",
      "conservation\n",
      "art\n",
      "polish\n",
      "highlights\n",
      "medicinal\n",
      "future\n",
      "n1\n",
      "benzothiepino\n",
      "scientific\n",
      "committee\n",
      "fifty\n",
      "years\n",
      "food\n",
      "note\n",
      "–\n",
      "quantum\n",
      "biology\n",
      "effects\n",
      "biological\n",
      "correction\n",
      "keith\n",
      "bioinorganic\n",
      "xv\n",
      "editorial\n",
      "6′\n",
      "calixarene\n",
      "40\n",
      "conference\n",
      "farber\n",
      "enzyme\n",
      "rechargeable\n",
      "bioorganic\n",
      "defined\n",
      "supramolecular\n",
      "iodovinyl\n",
      "nitration\n",
      "computational\n",
      "theoretical\n",
      "mechanical\n",
      "anniversary\n",
      "glossary\n",
      "renewable\n",
      "preface\n",
      "z\n",
      "great\n",
      "phytoprostanes\n",
      "war\n",
      "congress\n",
      "european\n",
      "1st\n",
      "analytical\n",
      "space\n",
      "prof\n",
      "rosemary\n",
      "dr\n",
      "11h\n",
      "heteroatom\n",
      "coordination\n",
      "laser\n",
      "greece\n",
      "sweet\n",
      "education\n",
      "nuclear\n",
      "organometallic\n",
      "light\n",
      "high\n",
      "material\n",
      "temperature\n",
      "solid\n",
      "state\n",
      "industry\n",
      "journal\n",
      "plasma\n",
      "phosphorus\n",
      "biomolecular\n",
      "pharmaceutical\n",
      "boron\n",
      "solutions\n",
      "organic\n",
      "sulfur\n",
      "polymers\n",
      "website\n",
      "thieme\n",
      "beyond\n",
      "chlorine\n",
      "international\n",
      "survey\n",
      "carini\n",
      "india\n",
      "nature\n",
      "proceeding\n",
      "engineers\n",
      "physical\n",
      "indeno\n",
      "initial\n",
      "organotin\n",
      "northwestern\n",
      "interference\n",
      "automated\n",
      "present\n",
      "r\n",
      "thymidine\n",
      "versus\n",
      "chemical\n",
      "purposes\n",
      "monkey\n",
      "within\n",
      "dendrimer\n",
      "tetrahydropyrimidines\n",
      "introduction\n",
      "dimethylhexane\n",
      "research\n",
      "protection\n",
      "alkyne\n",
      "crop\n",
      "reviews\n",
      "2015\n",
      "main\n",
      "group\n",
      "electron\n",
      "molecular\n",
      "electrochemistry\n",
      "678\n",
      "macrocycles\n",
      "selena\n",
      "perspectives\n",
      "moscow\n",
      "workshop\n",
      "modern\n",
      "aspects\n",
      "c5h5\n",
      "new\n",
      "use\n",
      "guide\n",
      "writing\n",
      "2003\n",
      "tetrahedron\n",
      "creativity\n",
      "prize\n",
      "nucleic\n",
      "templates\n",
      "acid\n",
      "liebig\n",
      "animal\n",
      "proteomics\n",
      "emphasis\n",
      "contributions\n",
      "contents\n",
      "mch\n",
      "macromolecular\n",
      "symposia\n",
      "tetramethylethylenediaminium\n",
      "history\n",
      "year\n",
      "second\n",
      "life\n",
      "металлопротеиназы\n",
      "ideas\n",
      "louis\n",
      "entry\n",
      "medicine\n",
      "трансформированных\n",
      "laboratory\n",
      "photochemistry\n",
      "berzelius\n",
      "–liclo\n",
      "phenomena\n",
      "solubility\n",
      "energy\n",
      "development\n",
      "sustainable\n",
      "pharmaceuticals\n",
      "pharmacy\n",
      "large\n",
      "hospital\n",
      "importance\n",
      "environmental\n",
      "environment\n",
      "review\n",
      "experiment\n",
      "atmospheric\n",
      "bpy\n",
      "ace\n",
      "toxicological\n",
      "marine\n",
      "communication\n",
      "short\n",
      "trimethylenebipyridine\n",
      "three\n",
      "editors\n",
      "self\n",
      "10\n",
      "top\n",
      "cited\n",
      "articles\n",
      "aquatic\n",
      "mediterranean\n",
      "systems\n",
      "macrocyclic\n",
      "titanocene\n",
      "sulfide\n",
      "conferences\n",
      "2004\n",
      "dynamic\n",
      "adaptive\n",
      "towards\n",
      "ansell\n",
      "better\n",
      "teaching\n",
      "way\n",
      "house\n",
      "report\n",
      "national\n",
      "applied\n",
      "1904\n",
      "issue\n",
      "special\n",
      "pure\n",
      "surgeons\n",
      "role\n",
      "africa\n",
      "south\n",
      "moo4\n",
      "oxyhydroxide\n",
      "world\n",
      "iupac\n",
      "clean\n",
      "students\n",
      "human\n",
      "views\n",
      "reporting\n",
      "interlanthanide\n",
      "units\n",
      "news\n",
      "concentration\n",
      "regulation\n",
      "chemistry”\n",
      "russia\n",
      "spain\n",
      "arts\n",
      "scientists\n",
      "fight\n",
      "2009\n",
      "results\n",
      "reader\n",
      "2010\n",
      "2014\n",
      "frontiers\n",
      "france\n",
      "diphenylphosphine\n",
      "host\n",
      "useful\n",
      "guest\n",
      "techniques\n",
      "dft\n",
      "flavor\n",
      "replication\n",
      "recognition\n",
      "connected\n",
      "elementary\n",
      "inorganic\n",
      "experimental\n",
      "test\n",
      "methodology\n",
      "diagnostic\n",
      "nonsteroidal\n",
      "calendar\n",
      "index\n",
      "subject\n",
      "author\n",
      "oo·\n",
      "content\n",
      "aerosol\n",
      "impacts\n",
      "ocean\n",
      "recommendations\n",
      "integrity\n",
      "frontier\n",
      "2e\n",
      "front\n",
      "matter\n",
      "2993\n",
      "645\n",
      "publishers\n",
      "ane\n",
      "photography\n",
      "image\n",
      "azaindole\n",
      "erratum\n",
      "alloying\n",
      "diisocyanohexane\n",
      "division\n",
      "american\n",
      "association\n",
      "boltzmann\n",
      "diet\n",
      "bromo\n",
      "meeting\n",
      "symposium\n",
      "fifth\n",
      "7186\n",
      "board\n",
      "mercury\n",
      "trans\n",
      "mccleverty\n",
      "29213\n",
      "vii\n",
      "29328\n",
      "atm\n",
      "flow\n",
      "cinnamomum\n",
      "standards\n",
      "de\n",
      "790\n",
      "chlorobis\n",
      "book\n",
      "progress\n",
      "korea\n",
      "antioxidants\n",
      "quadrupole\n",
      "contractions\n",
      "memorial\n",
      "nutritional\n",
      "bibliography\n",
      "methods\n",
      "bath\n",
      "colour\n",
      "diamides\n",
      "publisher\n",
      "wei\n",
      "biocatalysis\n",
      "click\n",
      "member\n",
      "commentary\n",
      "events\n",
      "krohn\n",
      "octakis\n",
      "scotland\n",
      "cover\n",
      "crude\n",
      "oil\n",
      "biomarkers\n",
      "climate\n",
      "plans\n",
      "change\n",
      "probed\n",
      "spread\n",
      "like\n",
      "management\n",
      "ocho•\n",
      "hrtem\n",
      "hfs\n",
      "2013\n",
      "love\n",
      "air\n",
      "laiiicuii\n",
      "pd−oo−x\n",
      "bio\n",
      "armour\n",
      "scales\n",
      "tree\n",
      "o\n",
      "fuel\n",
      "processing\n",
      "synthesis\n",
      "chemist\n",
      "2007\n",
      "water\n",
      "…\n",
      "b315474b\n",
      "dangling\n",
      "farmed\n",
      "stark\n",
      "oxalato\n",
      "pigs\n",
      "phenazine\n",
      "germany\n",
      "abstracts\n",
      "phosphoinositide\n",
      "signaling\n",
      "ethoxycarbonyl\n",
      "inc\n",
      "list\n",
      "2005\n",
      "addresses\n",
      "cellular\n",
      "‘a\n",
      "ltd\n",
      "optimized\n",
      "biosciences\n",
      "au4\n",
      "malaria\n",
      "biotechnology\n",
      "5z\n",
      "limited\n",
      "isomorphous\n",
      "biotin\n",
      "synthase\n",
      "computers\n",
      "healthcare\n",
      "12a\n",
      "volume\n",
      "29\n",
      "28\n",
      "amidines\n",
      "foreword\n",
      "26\n",
      "increase\n",
      "price\n",
      "needs\n",
      "unesco\n",
      "vanloon\n",
      "0199228867\n",
      "0521736695\n",
      "22\n",
      "stimulus\n",
      "benzamide\n",
      "corrections\n",
      "butterfly\n",
      "universe\n",
      "1\n",
      "confirmed\n",
      "nh2me2\n",
      "perspective\n",
      "27\n",
      "genetics\n",
      "thiolate−phosphine\n",
      "pyrazolo\n",
      "past\n",
      "cultural\n",
      "sensors\n",
      "clinically\n",
      "stresses\n",
      "cocoa\n",
      "crystal\n",
      "isobutyl\n",
      "invited\n",
      "jack\n",
      "tb\n",
      "tubes\n",
      "line\n",
      "supply\n",
      "nanotechnology\n",
      "safety\n",
      "first\n",
      "o2cr\n",
      "trade\n",
      "award\n",
      "microwave\n",
      "protein\n",
      "erythrocytes\n",
      "adenosyl\n",
      "right\n",
      "side\n",
      "phsn\n",
      "tb3\n",
      "marilyn\n",
      "john\n",
      "diary\n",
      "validation\n",
      "constructed\n",
      "discovery\n",
      "ronald\n",
      "c\n",
      "h2so4\n",
      "power\n",
      "simple\n",
      "complexity\n",
      "local\n",
      "crook\n",
      "corrigendum\n",
      "polymer\n",
      "bench\n",
      "cram\n",
      "1994\n",
      "ionic\n",
      "liquids\n",
      "errata\n",
      "salt\n",
      "build\n",
      "greener\n",
      "diagnostik\n"
     ]
    }
   ],
   "source": [
    "for word in list(garbage)[0:500]:\n",
    "    print(dictionary[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ziphian(corp)\n",
    "    li = []\n",
    "    ind=0\n",
    "    for doc in corp:\n",
    "        li+=[i for i,j in doc]\n",
    "    c = Counter(li)\n",
    "    c_li = [(k,v) for k,v in c.items()]\n",
    "    c_li_s = sorted(c_li,key=lambda x: x[1],reverse=True)\n",
    "    with open('ziphian.json','ab+') as f:\n",
    "    f.write('[')\n",
    "    for k,v in c_li_s[:-1]:\n",
    "        ex = json.dumps([dictionary[k],v])\n",
    "        f.write(ex)\n",
    "        f.write(',\\n')\n",
    "    ex = json.dumps([dictionary[c_li_s[-1][0]],c_li_s[-1][1]])\n",
    "    f.write(ex)\n",
    "    f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
